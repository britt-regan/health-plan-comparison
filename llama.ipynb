{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/britt/Documents/Northeastern/DS5500/Project/health-plan-comparison/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import fitz\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.listdir('2023 Competitor Docs')\n",
    "data = []\n",
    "\n",
    "for state_folder in directory:\n",
    "    state_path = '2023 Competitor Docs/' + state_folder\n",
    "    state_directory = os.listdir(state_path)\n",
    "\n",
    "    for file in state_directory:\n",
    "        file_path = state_path + '/' + file\n",
    "        pdf_file = fitz.open(file_path)\n",
    "\n",
    "        text = ''\n",
    "\n",
    "        for page in pdf_file:\n",
    "            extracted_text = page.get_text()\n",
    "            text += extracted_text + '\\n\\n'\n",
    "                    \n",
    "        data.append([state_folder, file, text])\n",
    "\n",
    "documents = pd.DataFrame(data, columns = ['state', 'file', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip spaces and dashes from file names\n",
    "documents['file'] = documents['file'].str.replace('-', '') #strip dashes\n",
    "documents['file'] = documents['file'].str.replace(' ', '') #strip spaces\n",
    "documents['file'] = documents['file'].str.replace('_', '') #strip underscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits_grid = pd.read_csv('Benefits Grid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits_grid = benefits_grid.rename(columns = {'CONTRACT_PLAN': 'contract_plan'})\n",
    "benefits_grid['contract_plan'] = benefits_grid['contract_plan'].str.replace(' ', '')\n",
    "benefits_grid['contract_plan'] = benefits_grid['contract_plan'].str.replace('-', '') #strip dashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only benefits grid columns we care about\n",
    "benefits_grid = benefits_grid[['County','Provider','contract_plan','Implant Coverage (Y/N)','Root Canal Coverage (Y/N)','Healthy Food Rollover','OTC Rollover (Y/N)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with NA\n",
    "benefits_grid = benefits_grid.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to group targets correctly\n",
    "def process_text(text):\n",
    "    y_variations = ['Y','Y ','Y  ','Y?','Y, one month will carry over to the next month only within the same calendar quarter','Y -- carries over each month and expires at the end of the year','Y -- $20 monthly allowance rolls over to next month and expires at the end of the year','Y -- $35 monthly allowance rolls over each month and expires at the end of the year','Y -- $30 monthly allowance rolls over each month and expires at the end of the year']\n",
    "    if isinstance(text, str):\n",
    "        for y_variation in y_variations:\n",
    "            if re.search(re.escape(y_variation), text, re.IGNORECASE):\n",
    "                return 'Y'\n",
    "        return 'N'\n",
    "    return 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process targets\n",
    "benefits_grid['Implant Coverage (Y/N)'] = benefits_grid['Implant Coverage (Y/N)'].apply(process_text)\n",
    "benefits_grid['Root Canal Coverage (Y/N)'] = benefits_grid['Root Canal Coverage (Y/N)'].apply(process_text)\n",
    "benefits_grid['Healthy Food Rollover'] = benefits_grid['Healthy Food Rollover'].apply(process_text)\n",
    "benefits_grid['OTC Rollover (Y/N)'] = benefits_grid['OTC Rollover (Y/N)'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits_grid['Implant Coverage (Y/N)'] = benefits_grid['Implant Coverage (Y/N)'].str.upper()\n",
    "benefits_grid['Root Canal Coverage (Y/N)'] = benefits_grid['Root Canal Coverage (Y/N)'].str.upper()\n",
    "benefits_grid['Healthy Food Rollover'] = benefits_grid['Healthy Food Rollover'].str.upper()\n",
    "benefits_grid['OTC Rollover (Y/N)'] = benefits_grid['OTC Rollover (Y/N)'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Documents to Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_list = benefits_grid[benefits_grid['contract_plan'] != 'EOC']['contract_plan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contract_plan(file_name):\n",
    "    for plan in plan_list:\n",
    "        if plan in file_name:\n",
    "            return plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents['contract_plan_file'] = documents.apply(lambda row : find_contract_plan(row['file']), axis = 1)\n",
    "documents['contract_plan_text'] = documents.apply(lambda row : find_contract_plan(row['text']), axis = 1)\n",
    "documents['contract_plan'] = documents.contract_plan_file.combine_first(documents.contract_plan_text)\n",
    "#documents = documents.drop(['contract_plan_text', 'contract_plan_file'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minor text cleaning to remove \\xa0 characters\n",
    "#documents['text'] = documents['text'].replace('\\xa0', ' ')\n",
    "documents['text'] = documents['text'].apply(lambda x: re.sub(r'\\xa0', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for start and end phrases\n",
    "start_phrase = 'You will see this apple next'\n",
    "end_phrase = 'What services are not covered'\n",
    "\n",
    "# Function to extract text between the start and end phrases\n",
    "def extract_text(text):\n",
    "    start_index = text.find(start_phrase)\n",
    "    end_index = text.find(end_phrase, start_index + len(start_phrase))\n",
    "    if start_index != -1 and end_index != -1 and start_index < end_index:\n",
    "        return text[start_index + len(start_phrase):end_index].strip()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply function to the text column\n",
    "documents['text_cleaned'] = documents['text'].apply(extract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge document data with benefits grid\n",
    "dataset = pd.merge(benefits_grid, documents, how = 'inner', on = ['contract_plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = dataset[\"text_cleaned\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = open('docs.pkl', 'ab')\n",
    "pickle.dump(docs, dataset_file)\n",
    "dataset_file.close()\n",
    "\n",
    "dataset_file = open('dataset.pkl', 'ab')\n",
    "pickle.dump(dataset, dataset_file)\n",
    "dataset_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = open('docs.pkl', 'rb')\n",
    "docs = pickle.load(dataset_file)\n",
    "dataset_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def check_coverages(doc):\n",
    "    root_canals = []\n",
    "    implants = []\n",
    "    otc = []\n",
    "    food = []\n",
    "    \n",
    "    with open('doc.txt', 'w') as f:\n",
    "        f.write(doc)\n",
    "    \n",
    "    loader = TextLoader('doc.txt')\n",
    "    documents = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size = 512, chunk_overlap = 0)\n",
    "    texts = splitter.split_documents(documents)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "        model_kwargs = {'device': 'cpu'})\n",
    "\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "    db.save_local('faiss')\n",
    "\n",
    "    template = \"\"\"You are given a set of subreports indicating whether various items are mentioned.\n",
    "\n",
    "    {question}  If they are, the final response for that item should be Yes.\n",
    "    Include no other information besides what is asked for.  If any of the information is unclear, the response should be No.\n",
    "\n",
    "    Final report format:\n",
    "    Root canals mentioned: (Yes or No)\n",
    "    Implants mentioned: (Yes or No)\n",
    "    OTC benefits rollover: (Yes or No)\n",
    "    Healthy food benefits rollover: (Yes or No)\n",
    "\n",
    "    Set of subreports: {context}\n",
    "    \"\"\"\n",
    "\n",
    "    llm = CTransformers(model = 'llama-2-7b-chat.ggmlv3.q8_0.bin',\n",
    "                    model_type = 'llama',\n",
    "                    config = {'max_new_tokens': 165, 'temperature': 0.01})\n",
    "\n",
    "    db = FAISS.load_local('faiss', embeddings)\n",
    "    retriever = db.as_retriever(search_kwargs = {'k': 2})\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template = template,\n",
    "        input_variables = ['context', 'question'])\n",
    "\n",
    "    qa_llm = RetrievalQA.from_chain_type(llm = llm,\n",
    "                                     chain_type = 'stuff',\n",
    "                                     retriever = retriever,\n",
    "                                     return_source_documents = True,\n",
    "                                     chain_type_kwargs = {'prompt': prompt}\n",
    "                                     )\n",
    "    \n",
    "    prompt = 'Create a final report indicating whether these items are mentioned in any of the subreports.'\n",
    "    \n",
    "    output = qa_llm({'query': prompt})\n",
    "    results = output['result']\n",
    "\n",
    "    index_rt = results.find(\"Root canals mentioned: \")\n",
    "    letter_rt = results[index_rt + len(\"Root canals mentioned: \")]\n",
    "    root_canals.append(letter_rt)\n",
    "        \n",
    "    index_im = results.find(\"Implants mentioned: \")\n",
    "    letter_im = results[index_im + len(\"Implants mentioned: \")]\n",
    "    implants.append(letter_im)\n",
    "        \n",
    "    index_otc = results.find(\"OTC benefits rollover: \")\n",
    "    letter_otc = results[index_otc + len(\"OTC benefits rollover: \")]\n",
    "    otc.append(letter_otc)\n",
    "        \n",
    "    index_food = results.find(\"Healthy food benefits rollover: \")\n",
    "    letter_food = results[index_food + len(\"Healthy food benefits rollover: \")]\n",
    "    food.append(letter_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverages(doc):\n",
    "    root_canals = []\n",
    "    implants = []\n",
    "    otc = []\n",
    "    food = []\n",
    "    \n",
    "    with open('doc.txt', 'w') as f:\n",
    "        f.write(doc)\n",
    "    \n",
    "    loader = TextLoader('doc.txt')\n",
    "    documents = loader.load()\n",
    "\n",
    "    model = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size = 1600,\n",
    "                                              chunk_overlap = 20,)\n",
    "    \n",
    "    texts = splitter.split_documents(documents)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name = model,\n",
    "        model_kwargs = {'device': 'cpu'},\n",
    "        encode_kwargs = {'normalize_embeddings': True})\n",
    "    \n",
    "    embeddings.client.tokenizer.pad_token =  embeddings.client.tokenizer.eos_token\n",
    "\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "    db.save_local('faiss')\n",
    "\n",
    "    template = \"\"\"You are given a set of subreports indicating whether various items are mentioned.\n",
    "\n",
    "    {question}  If they are, the final response for that item should be Yes.\n",
    "    Include no other information besides what is asked for.  If any of the information is unclear, the response should be No.\n",
    "\n",
    "    Final report format:\n",
    "    Root canals mentioned: (Yes or No)\n",
    "    Implants mentioned: (Yes or No)\n",
    "    OTC benefits rollover: (Yes or No)\n",
    "    Healthy food benefits rollover: (Yes or No)\n",
    "\n",
    "    Set of subreports: {context}\n",
    "    \"\"\"\n",
    "\n",
    "    # llm = CTransformers(model = model,\n",
    "    #                     model_type = 'llama',\n",
    "    #                     config = {'max_new_tokens': 200, 'temperature': 0.01})\n",
    "\n",
    "    generation_config = GenerationConfig.from_pretrained(model)\n",
    "    generation_config.max_new_tokens = 200\n",
    "    generation_config.temperature = 0.01\n",
    "    \n",
    "    llm = pipeline(\n",
    "        'text-generation',\n",
    "        model = model,\n",
    "        # tokenizer=tokenizer,\n",
    "        generation_config = generation_config,\n",
    "    )\n",
    "\n",
    "    db = FAISS.load_local('faiss', embeddings)\n",
    "    retriever = db.as_retriever(search_kwargs = {'k': 2})\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template = template,\n",
    "        input_variables = ['context', 'question'])\n",
    "\n",
    "    qa_llm = RetrievalQA.from_chain_type(llm = llm,\n",
    "                                     chain_type = 'stuff',\n",
    "                                     retriever = retriever,\n",
    "                                     return_source_documents = True,\n",
    "                                     chain_type_kwargs = {'prompt': prompt},\n",
    "                                     )\n",
    "    \n",
    "    prompt = 'Create a final report indicating whether these items are mentioned in any of the subreports.'\n",
    "    \n",
    "    output = qa_llm({'query': prompt})\n",
    "    results = output['result']\n",
    "\n",
    "    index_rt = results.find(\"Root canals mentioned: \")\n",
    "    letter_rt = results[index_rt + len(\"Root canals mentioned: \")]\n",
    "    root_canals.append(letter_rt)\n",
    "        \n",
    "    index_im = results.find(\"Implants mentioned: \")\n",
    "    letter_im = results[index_im + len(\"Implants mentioned: \")]\n",
    "    implants.append(letter_im)\n",
    "        \n",
    "    index_otc = results.find(\"OTC benefits rollover: \")\n",
    "    letter_otc = results[index_otc + len(\"OTC benefits rollover: \")]\n",
    "    otc.append(letter_otc)\n",
    "        \n",
    "    index_food = results.find(\"Healthy food benefits rollover: \")\n",
    "    letter_food = results[index_food + len(\"Healthy food benefits rollover: \")]\n",
    "    food.append(letter_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/britt/.cache/torch/sentence_transformers/meta-llama_Llama-2-7b-chat-hf. Creating a new one with MEAN pooling.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:32<00:00, 76.06s/it] \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    check_coverages(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_coverage(doc):\n",
    "    summaries = []\n",
    "    \n",
    "    with open('doc.txt', 'w') as f:\n",
    "        f.write(doc)\n",
    "    \n",
    "    loader = TextLoader('doc.txt')\n",
    "    documents = loader.load()\n",
    "\n",
    "    model = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size = 1600,\n",
    "                                              chunk_overlap = 20,)\n",
    "    \n",
    "    texts = splitter.split_documents(documents)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name = model,\n",
    "        model_kwargs = {'device': 'cpu'},\n",
    "        encode_kwargs = {'normalize_embeddings': True})\n",
    "    \n",
    "    embeddings.client.tokenizer.pad_token =  embeddings.client.tokenizer.eos_token\n",
    "\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "    db.save_local('faiss')\n",
    "\n",
    "    template = \"\"\"You are reviewing coverage documents in order to summarize the dental benefits covered by a health plan.\n",
    "    {question}, in particular the following:\n",
    "\n",
    "    - Annual maximum for dental coverage.\n",
    "    - Member cost share (coinsurance) for dental benefits.\n",
    "    - What dental services and procedures are covered by the plan?\n",
    "    - Are periodtonal surgery and dental implants covered?\n",
    "    - What does the member pay in-network vs. out of network?\n",
    "\n",
    "    Coverage documents: {context}\n",
    "    \"\"\"\n",
    "\n",
    "    # llm = CTransformers(model = model,\n",
    "    #                     model_type = 'llama',\n",
    "    #                     config = {'max_new_tokens': 200, 'temperature': 0.01})\n",
    "\n",
    "    generation_config = GenerationConfig.from_pretrained(model)\n",
    "    generation_config.max_new_tokens = 200\n",
    "    generation_config.temperature = 0.01\n",
    "    \n",
    "    llm = pipeline(\n",
    "        'text-generation',\n",
    "        model = model,\n",
    "        # tokenizer=tokenizer,\n",
    "        generation_config = generation_config,\n",
    "    )\n",
    "\n",
    "    db = FAISS.load_local('faiss', embeddings)\n",
    "    retriever = db.as_retriever(search_kwargs = {'k': 2})\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template = template,\n",
    "        input_variables = ['context', 'question'])\n",
    "\n",
    "    qa_llm = RetrievalQA.from_chain_type(llm = llm,\n",
    "                                     chain_type = 'stuff',\n",
    "                                     retriever = retriever,\n",
    "                                     return_source_documents = True,\n",
    "                                     chain_type_kwargs = {'prompt': prompt},\n",
    "                                     )\n",
    "    \n",
    "    prompt = 'Summarize the dental benefits if they are present'\n",
    "    \n",
    "    output = qa_llm({'query': prompt})\n",
    "    results = output['result']\n",
    "    summaries.append(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
